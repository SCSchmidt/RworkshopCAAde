---
title: "Skript R Workshop @ CAA de 2019"
author: "Sophie C. Schmidt"
date: "4 September 2019"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      eval = FALSE)
```

## Einführung


### Programmieren 

Programmieren ist so schwer nicht. Ich ersetze das "klicken auf einen button" mit "Text, der genau sagt, was getan werden soll". Man nennt die Umsetzungsform jedoch nicht umsonst "ProgrammierSPRACHE". Wie bei einer echten Sprache, muss man sich an gewisse Regeln halten. Im Gegensatz zu normalen menschlichen Sprachen, verzeiht einem der Computer jedoch kleine Fehler nicht. Das ist eigentlich die größte Schwierigkeit: Exakt korrekt zu schreiben. Keine Kommafehler, keine Klammer vergessen, Groß- und Kleinschreibung beachten... 

Analysen in Code (egal ob R oder Python oder eine andere Skript- oder Programmiersprache) haben den großen Vorteil, dass sie deutlich leichter reproduzierbar und replizierbar sind als welche, die in Maus-gesteuerter Software erstellt werden (siehe alles von Ben Marwick). Ich kann den Code jemand anderem geben und er/sie kann bis ins letzte Detail nachvollziehen, was berechnet wurde. Benutze ich keinen Code brauche ich dafür Beschreibungen, die eventuell ausarten könnten. 

Wenn sich in meinem Datensatz eine Kleinigkeit ändert (es könnte ja mal sein, dass eventuell ein Fehler passiert war), kann ich die gesamte Analyse sehr sehr schnell einfach wieder durchführen -- der Code ist ja noch da, und der bleibt gleich. Wiederhole ich nach einem Jahr eine Analyse mit anderen Daten, geht das sehr sehr schnell -- der Code kann einfach wieder benutzt werden. 

Das ist ein Riesenvorteil. 


### Warum R

R wurde 1992 von Ross Ihaka und Robert Gentleman, zwei Statistikern, in Auckland als open und free source - Alternative zu der Sprache "S" entwickelt. Da sie auch plattformunabhängig ist, ist sie immer und überall benutzbar. 

R wurde von Statistikern entwickelt und hat deshalb insbesondere für statistische Analysen eine große Menge an Paketen und definierten Funktionen, die von der Gemeinschaft beständig weiterentwickelt und erweitert werden. Sie werden auf dem Comprehensive R Archive Network (CRAN) zur Verfügung gestellt. Damit findet man eigentlich für jedes Problem eine Lösung. Inzwischen kann man mir R ein GIS ersetzen, es lassen sich interaktive und animierte Graphiken erstellen, Websites und Präsentationsfolien bauen und sicherlich noch mehr, das ich nicht kenne... 

Online gibt es eine Menge Ressourcen und Hilfestellungen, die einem die Arbeit mit R erleichtern. Zugegebenermaßen ist der Einstieg nicht ganz leicht, aber der Mehraufwand lohnt sich! Es gibt eine wachsende Gemeinschaft von Archäologen, die es nutzen. 

R selber hat keine schöne Benutzeroberfläche, sondern wird von der Konsole aus "gesteuert". Dafür benutzern wir Rstudio (es gibt noch andere wie RCommander, RGui), das einem Skript, Konsole, Programmierumgebung und noch weiteres übersichtlich in Fenstern anordnet. 



## Einführung in die Grundlagen			
R ist eine objektorientierte Sprache. Das heißt, alles ist in R entweder ein Objekt oder eine Funktion. Eine Funktion "macht" immer etwas mit einem Objekt. Wie im Mathe-Unterricht: f(x) = 2*x rechnet für jedes x den zugehörigen Wert (y) aus, der genau das Doppelte von x ist. Nur können die Funktionen in R deutlich komplizierter werden... 

Die Funktionen sind in Paketen gespeichert, die sich auf einander beziehen: Wenn in Paket A eine Funktion f(x) liegt, in der die Funktion g(x) aus Paket B benutzt wird, besteht eine Abhängigkeit (dependency) von Paket A zu Paket B. Installiere ich Paket A, wird in der Regel automatisch Paket B mitinstalliert, damit ich die Funktion f(x) auch wirklich benutzen kann. Manchmal kommen aber trotzdem Fehlermeldungen wie "error: could not find function", dann kann es sein, dass eine dependency nicht mitinstalliert wurde ODER nicht geladen wurde. Denn: Wenn  wir Funktionen aus einem Paket brauchen, müssen wir es installieren und jedesmal, wenn wir es benutzen, am Anfang einer R-Sitzung laden (mit der *library* oder *require*-Funktion, Beispiele später). Die wichtigsten Funktionen sind in R "base" vorinstalliert. Manchmal haben Funktionen in unterschiedlichen Paketen den gleichen Namen. Dann gibt R eine Warnung aus, "objects are masked", d.h. die Funktionen des neu geladenen Pakets "überschreiben" die alten. Nicht irritieren lassen, meistens interessiert uns das nicht.

Funktionen erkennt man daran, dass hinter dem Funktionsbefehl oder -namen in runden Klammern die Objekte stehen, auf die die Funktion angewandt wird sowie Parameter, wie diese Funktion angewandt werden soll. Ein einfaches Beispiel: 

mean(x)

--> "mean" ist der Funktionsname, auf x wird die Funktion ausgeführt.

Was könnte x, können Objekte sein? 
(Tatsächlich können Funktionen auch als Objekte behandelt werden)

Wir betrachten hier nur die wichtigsten Typen von Objekten: Skalare, Vektoren und Dataframes. Diese werden in R in der Regel durch Variablen kodiert. Ein Skalar ist nur *ein einziger* Wert. Es kann sich um eine Zahl handeln, als *integer* also Ganzzahl oder *numeric* als Kommazahl. Ein Skalar kann aber auch eine Abfolge von Buchstaben sein, *character* genannt, also ein Wort oder ein Kürzel. 

Vektoren sind eine Reihe von Skalaren gleichen Typs. Also eine Reihe von *integer* oder mehrere *character*-Einträge hintereinander. Wenn aber in einem Vektor sowohl Zahlen als auch Texteintragungen auftauchen, werden auch die Zahlen als Text gespeichert und man kann nicht mehr mit ihnen rechnen. Einen Vektor kann man sich auch als Spalte einer Tabelle vorstellen, wobei die Spalteneinträge immer die gleiche Datentypen beinhalten müssen. 

Mehrere Vektoren können zu einem *Dataframe* zusammengefasst werden. Ein Dataframe ist wie eine Tabelle: Die unterschiedlichen Spalten können unterschiedliche Datentypen beinhalten und besitzen Spaltennamen. Die Zeilen werden als "row.names" entweder gezählt oder tatsächlich benannt.

Beispiele kommen gleich!

Noch eine Kleinigkeit vorneweg:

R ist case-sensitive! Groß- und Kleinschreibung sind also stets zu beachten. Für Objektnamen (zum Beispiel von Funktionen und Variablen) sind neben den alphanumerischen Zeichen auch der Punkt und der Unterstrich erlaubt. Objektnamen mit Unterstrich sind allerdings eher selten anzutreffen, häufiger wird der Punkt benutzt, um Objektbezeichner zu strukturieren. Leerzeichen sind nie eine gute Idee!  



## Ins kalte Wasser!
Rstudio öffnen und Fenster anschauen:
oben rechts: Environment = Programmierumgebung, history = letzte Befehle; 
unten rechts: files = Ordner, in dem ich gerade arbeite, plots = Reiter unter dem Bilder gezeigt werden, packages = welche Pakete sind installiert und geladen, help = Hilfe (immer gut!)
unten: Console und Terminal.


Als eiserne Regel benutzt man immer ein Skript, um Code zu schreiben und nicht direkt die Konsole. Der Vorteil ist: Alles im Skript kann ich speichern (und sollte ich auch möglichst häufig, Strg+S is your best friend), was ich in die Konsole tippe, wird nicht gespeichert. Also Skript anlegen und abspeichern ist das erste was wir machen. Dafür gibt es links oben ein kleines Symbol (weißes Blatt mit grün umrandeten +). 

Mit dem # Hashtag kommentiere ich Text aus. D. h. der Text wird nicht als Code behandelt. Sehr sehr wichtig ist das, weil ich damit meinen Code kommentieren kann. Kommentare erleichtern einem das Leben massiv. In der Regel hat man nämlich nach spätestens einer Woche vergessen, was der Code tun konnte und sollte und wenn dann daneben ein hilfreiches Kommentar zu finden ist, erinnert man sich wieder.

Deswegen sollten wir alle in die oberste Zeile schreiben, was das für eine Datei ist und wer sie erstellt hat.

Die Skriptdatei ist eine einfache Textdatei, die die Dateiendung .R besitzen. Das Format .RData (oder kurz .Rda) wird verwendet, um ein R-Objekt, beispielsweise einen Datensatz, oder eine Kollektion von R-Objekten, also Daten und Funktionen, im R internen binären serialisierten Format abzuspeichern, wobei diese Dateien zusätzlich standard-komprimiert sind. Die gesamte Arbeitsumgebung kann so ebenfalls als .RData-Datei gespeichert werden. 

Der in einem Skript geschriebene Code wird nicht automatisch sofort ausgeführt, sondern die Ausführung muss beauftragt werden, in dem man ihn mit Strg + ENTER zur Konsole sendet. Was in die Konsole eingetippt wird, wird sofort durch ENTER ausgeführt.

*notes to self:

- grüne und rote Klebis verteilen und Prinzip erklären

- life coding ausprobieren am Anfang* 


### Taschenrechner

Man kann R wie einen Taschenrechner benutzen, die einfachen Rechenoperationen stehen zur Verfügung:

```{r}
3 + 2
```


```{r}
5 - 7
```


```{r}
5 * 2
```


```{r}
100 / 10
```

Oder auch:
```{r}
3*(4+2)
```


Rechenergebnisse, wie z.B. das Ergebnis von 3*(4+2) können in Variablen gespeichert werden. Die Zuweisung des Ergebnisses zu einer Variablen geschieht mit dem Zuweisungsoperator “<-“ und sieht im allgemeinen folgenderweise aus:

Variablenname <- Befehl

Wird nacheinander mehrmals dergleichen Variablen verschiedene Ergebnisse zugewiesen, enthält die Variable das Ergebnis der letzten Zuweisung. Um nachzusehen, was eine Variable enthält, kann man den Variablennamen in die Konsole eingeben und mit Enter abschicken oder oben rechts unter Environment nachsehen. R merkt sich NICHTS, es sei denn, ich weise es einer Variablen zu. Das heißt auch, wenn ich einen Befehl / eine Formel auf einen Datensatz anwende, bleibt das nur langfristig bestehen, wenn ich mit dem Befehl gleichzeitig entweder meinen alten Datensatz überschreibe ODER einen neuen entstehen lasse.

Ergo:
```{r}
x <- 3*(4+2) 
```

Oben rechts ist jetzt unter dem Reiter "Environment" der Wert "x" erschienen. Wir können dort immer ablesen, welche Variablen wir zur Zeit definiert haben. 

Mit x kann ich jetzt weiterrechnen:
```{r}
y <- x+2
```

Da diese beiden Werte den gleichen Typ haben (*numeric*), kann ich sie in einem Vektor zusammenfassen:

```{r}
z <- c(x,y)
```
Was ist passiert?

Das c() markiert, dass ich mehrere Werte in einer Reihe eingebe, die zusammengehören sollen. Mit <- habe ich diese Reihe der Variablen z zugeordnet.

Wenn ich das alles noch einmal mit anderen Werten mache, kann ich aus den zwei Vektoren einen Dataframe erstellen:
```{r}
a <- "Hund"
b <- "Katze"
```

Die Hochkommas erklären R, dass es sich um Text handelt und nicht um Objekte (also andere Variablen). Vergisst man sie, kommt die Fehlermeldung "object 'Hund' not found", weil R nach etwas, das 'Hund' heißt, sucht und nicht findet.

Jetzt lassen sich diese beiden in einen Vektor zusammengefügt:
```{r}
ab <- c(a,b)
```

Unter "Environment" oben rechts in Rstudio befinden sich jetzt alle neuen Variablen, die wir definiert haben. Wir können auch sehen, dass  "ab" "chr" -- also ein "character"-Vektor -- ist, während z als "num" -- numerical -- markiert wird.

Jetzt bauen wir aus diesen beiden Vektoren einen Dataframe:
```{r}
df <- data.frame(z, ab)
```

Unter Environment erscheint unter der Überschrift "Data" jetzt df. Auf den blauen Pfeil kann man klicken und sich anschauen, woraus der Dataframe zusammengesetzt ist. Wir können ihn uns auch anschauen, entweder durch "draufklicken" oder per Code:

```{r}
View(df)
```

Cool! Wir haben Daten!

Aber eigentlich wollten wir archäologische Daten benutzen. Netterweise gibt es Menschen, die eine Menge archäologischer Daten als R-Paket zusammengeschnürt haben und zur Verfügung gestellt haben (David L. Carlson und Georg Roth). Installieren wir also das erste Paket! Der Befehl ist *install.packages* und das Paket heißt "archdata":

```{r}
install.packages("archdata")
```

Nach erfolgreicher Installation (roter Text heißt in R nicht, dass Fehler passiert sind!), müssen wir das Paket noch in unsere Sitzung laden, damit wir damit umgehen können:

```{r}
library(archdata)
```

Im Paket archdata liegen mehrere Datensätze. Informationen zu dem Paket finde ich entweder unten rechts unter dem Reiter "Help" (in der Suche nach archdata suchen) oder mit diesem Code:

```{r}
?archdata
```

Ein einfaches Fragezeichen vor einem Funktions- oder Paketnamen führt einen zu der R-internen Hilfe. Immer ein guter Anfang, wenn irgendetwas nicht klappt (und Tipp-Fehler schon ausgeschlossen wurden).

Wir benutzen als erstes den Datensatz "BACups". Er wurde (wie die anderen) im RData-Format abgespeichert, weswegen wir ihn jetzt leicht mit einem einzigen Befehl in das Programm laden können:

```{r}
data("BACups")
```

Eigene Datensätze lassen sich am leichtesten als csv, aber auch als excel-Datei in R laden. R kann man auch mit Datenbanken verbinden und es gibt inzwischen Pakete, die PDF-Tabellen für einen auslesen. Infos dazu gibt's am Ende.

Wir sollten uns den Datensatz aber vorher einmal kurz angucken. Wie ging das noch einmal?


## Lagemaße u. ä.
Diesen Datensatz können wir jetzt schon einmal erkunden. Zum Beispiel uns die einzelnen Spalten anschauen.

- $  das Dollarzeichen steht zwischen Dataframe und dem Vector im Dataframe: df\$vector, damit wählen wir also den Vector ("die Spalte") an.


```{r}
BACups$Phase 
```

Was R mir jetzt einfach "ausspuckt" ist die Abfolge der Werte, die in der Tabellenspalte "Phase" stehen, wobei die Zahlen in eckigen Klammern die Positionen markieren. Außerdem sagt er mir wie viele "levels" der Vektor hat, also wie viele unterschiedliche Werte und wie diese heißen: Protoappenine und Subappenine. 


Tun wir das gleiche für einen numerischen Vektor:

```{r}
BACups$RD
```
Das sind die Werte des Randdurchmessers. Ein bisschen unübersichtlich, nicht wahr?

Wenden wir doch ein paar Funktionen darauf an, um uns einen Überblick zu verschaffen. Wir weisen den durch die Funktion errechneten Wert immer gleich einer Variable zu:  

Was ist der Mittelwert?
```{r}
RD_mean <- mean(BACups$RD) 
```
Du Funktion *mean* wird auf die Spalte "RD" des Dataframes "BACups" angewandt. 

Und der Median?
```{r}
RD_med <- median(BACups$RD)
```

Standardabweichung?
```{r}
RD_sd <- sd(BACups$RD)
```

Varianz?
```{r}
RD_var <- var(BACups$RD)
```

Größter und kleinster Wert?
```{r}
RD_range <- range(BACups$RD)
```

Wie viel Werte sind das eigentlich insgesamt? Also wie viele Zeilen im Datensatz?
```{r}
n_BACups <- nrow(BACups)
```

Geht das vielleicht etwas schneller?
```{r}
summary(BACups$RD)
```
Nunja, zumindest Minimal- und Maximalwerte, Median, Mittelwert und Quantile lassen sich so auf einen Blick anzeigen.

### Bestimmte Bereiche eines Datensatzes auswählen

- Eckige Klammern [ ]: Sie sind spannend, weil man mit ihnen Zeilen, Spalten und Felder eines Dataframes anwählen kann. Ein kleines Beispiel:

Will ich in dem Datensatz BACups zB die allererste Information (1. Zeile, 1. Spalte, was steht da?) herausholen, geht das so:

```{r Daten anwählen 1}

BACups_1_1 <- BACups[1,1]
```

Wie check ich, ob es geklappt hat? Richtig, oben rechts unter "Environment" steht jetzt BACups_1_1.

Ich kann aber auch die gesamte erste Zeile auslesen:

```{r Daten anwählen 2}

BACups_1 <- BACups[1,]
# BACups_1 ist rechts unter "data", weil es sich um einen Vector handelt. 1 observation, 6 variables steht daneben.
```

Natürlich lassen sich auch Spalten auswählen, hier die erste:

```{r Daten auswählen 3}

BACups_x_1 <- BACups[,1]
```

Folgerichtig kann man sich merken: In der eckigen Klammer hinter dem Datensatz kann man mit der ersten Zahl die Zeile bestimmen und mit der zweiten Zahl hinter einem Komma die Spalte. Gerade Spalten haben häufig Namen, die kann man für die Auswahl auch nutzen. Aber dazu kommt später noch ein Beispiel.

Negativauswahl gibt es natürlich auch. Also: Gib mir alles außer diese Spalte:

```{r Daten auswählen 4}
BACups_vieles <- BACups[, -2]
```

Alles außer Spalte 2 ist jetzt dem neuen Datensatz BACups_vieles zugewiesen worden


Ganz toll ist auch die Auswahlmöglichkeit "von a bis x". Das geht mit Doppelpunkt:

```{r Daten auswählen 5}
BACups_x <- BACups[c(10:20),]
```

Schaut euch an, was entstanden ist. Alles klar?

Wie oben, hab ich dem Programm mit c() gesagt, dass die Werte zusammengehören. Mit Doppelpunkt sage ich dann vom 10. bis zum 20. Wert. Da die Zahlen VOR dem Komma sind, erklär ich R, dass ich gern die Zeilen ausgewählt hätte.

Häufig brauchen wir aber nicht irgendwelche 1. Zeile oder 2. Reihe, sondern alle Einträge mit einem bestimmten Wert. z. B. nur die protoappeninen bronzezeitlichen Tassen. Hier führen viele Wege nach Rom:


## Daten auswählen

Wie ist also der Mittelwert des Randdurchmessers nur von protoappeninen bronzezeitlichen Tassen? 
Dafür (wie so für so vieles) gibt es unterschiedliche Wege in R. Schauen wir uns zwei kurz an: 

1. *subset*:

Diese Funktion gehört zu base R. Ich erstelle einen neuen Datensatz, der besteht aus dem alten Datensatz, da wo in der Spalte Phase genau (Operator "==") "Protoappenine" steht. Ich hab den Code mal kommentiert: 

```{r}
# erstellen eines neuen Datensatzes nur der protoappeninen Tassen
BACups_proto <- subset(BACups, BACups$Phase == "Protoapennine")

# Mittelwert berechnen:
mean(BACups_proto$RD)
```

2. *filter*

Die Filter-Funktion gehört zum sogenannten "tidyverse". Das Tidyverse ist wie ein bestimmter Dialekt von R. Eine Reihe von Paketen folgt diesem Dialekt und diese Pakete arbeiten besonders gut miteinander. Da diese neuen Pakete auch einiges vereinfachen, erfreuen sie sich zunehmender Beliebtheit und wenn man nach Lösungen googelt, findet man Anleitungen, die "tidy" Lösungen erklären. Im Tidyverse gibt es eine Besonderheit, die man kennen sollte: Die sogenannte "*pipe*". Mit dem Befehl %>% wird das Ergebnis einer Zeile in die nächste überführt. 

Im Beispiel schicke ich damit den gesamten Datensatz BACups in den Filter, der in der nächsten Zeile beschrieben wird, "filtere" ihn und schick ihn gefiltert weiter in die nächste Zeile, in der ich die Spalte definiere und in die letzte, wo es dann um die Berechnung des Mittelwertes geht:

```{r}
# filter funktion
library(dplyr)
# zur Vereinfachung der Pipe gibt es 
library(magrittr)

BACups %>%
  filter(Phase == "Protoapennine") %>%
  use_series(RD) %>%    # das sagt, nimm die Spalte RD, braucht Paket magrittr
  mean()

```

Wie man sieht, ist der "Kernbefehl" (" Phase == "Protoapennine" ") fast genau gleich wie bei der subset-Funktion. Es sind auch nicht weniger Zeilen Code. Es ist aber eventuell lesbarer. Und wenn ich mir vorstelle, dass ich meine Daten vllt noch nach 20 anderen Variablen filtern möchte, will ich nicht jedesmal einen extra Datensatz erstellen müssen. Manchmal wird es dann schwierig, sich sinnvolle Namen für die Datensätze auszudenken. So sehe ich immer, welche Filter ich genau angewandt habe. Allerdings: Brauche ich diese Datensätze noch für andere Berechnungen, ist subset die bessere Lösung. Oder ich weise das gefilterte einer Variablen zu, das geht auch:

```{r}
BACups_protapp <- BACups %>%
  filter(Phase == "Protoapennine")
```


## Funktionen schreiben

Wir haben jetzt schon Funktionen angewandt. Man kann sich in R aber auch Funktionen selber definieren. Die Syntax dafür ist immer gleich:

myfunction <- function(x) {
das wird mit x passieren
}

Die neue Funktion heißt "myfunction", sie wird auf eine Variable x angewandt und was mit x passiert, wird in den geschweiften Klammern definiert. Stellen wir uns vor, ich möchte eine Funktion für die Berechnung des doppelten Mittelwertes. Die könnte z. B. so aussehen:

```{r}
zwei_m <- function(x){
  2*sum(x)/length(x)
  }
```
Ich rechne zwei mal die Summe von x (d.h. x muss ein Vektor sein) und teile dies durch die Länge des Vektors (Anzahl der Einträge). Ich nenne die Funktion zwei_m.

zwei_m kann ich jetzt anwenden:

```{r}
zwei_m(BACups$RD)
```

Es heißt, wenn man eine Abfolge von Berechnungen mehr als 3mal benutzt, sollte man sie in eine Funktion packen, damit man den Code nicht immer kopieren und einfügen muss. Außerdem kann man so Fehler vermeiden, weil man nur noch die Funktion aufrufen muss und nicht mehr den ganzen Code wiederholen.



Beides funktioniert gleichermaßen gut.

# Pause							15min

Jetzt geht es um die Erstellung von Graphen. Hier gibt es tausende von Möglichkeiten und es werden immer mehr entwickelt. 

In base hat R sehr einfache Funktionen, mit denen man sehr schnell gute funktionale Graphiken erstellen kann, z. B.:

```{r}
hist(BACups$RD)
```
Auch in r-base kann man an den Graphiken noch viele Veränderungen vornehmen (sowohl an der Berechnung der Graphik als auch was Titel, Achsenbeschriftung und ähnliches angeht). Allerdings sind diese Graphiken nicht so elegant und ich selber arbeite mit ggplot: 

## ggplot

ggplot2 ist ein Paket, dase von Hadley Wickham entwickelt wurde, und viele Funktionen zur Visualisierung von Daten bietet (für eine Übersicht und Inspirationen siehe z. B: http://r-statistics.co/Top50-Ggplot2-Visualizations-MasterList-R-Code.html und https://www.r-graph-gallery.com/). Es folgt einer eigenen Logik, der "Grammatik der Diagramme" und gehört zum Tidyverse. Grundlegend ist eine Art "Layer-Konzept", dass ich mit jeder weiteren Zeile Code ein neues Layer zu dem Diagramm hinzufüge, wie bei der Bildbearbeitung mit Photoshop oder Gimp.

Erarbeiten wir uns das Schritt für Schritt.

3 Dinge gibt es in jedem ggplot, die definiert werden müssen:

- Welche Daten es benutzen soll ggplot(data = ), 

- welche Art von Diagramm es bauen soll (geom) und 

- wie das Diagramm aussehen soll (aes() von aesthetics), damit überhaupt etwas entsteht, also z. B., was auf der x- und der y-Achse abgetragen werden soll.

Alles andere danach sind reine Verschönerungsmaßnahmen. Mit "scales" lassen sich die Achsen und Legenden verändern, mit "theme" Hintergrundfarbe u. ä. (für mehr Infos siehe:  https://r-intro.tadaa-data.de/book/visualisierung.html )

Nehmen wir uns ein Beispiel vor und erarbeiten es uns der Reihe nach.


# Ein Säulendiagramm
Ein Säulendiagramm eignet sich zur Darstellung nominaler und ordinaler Variablen. Ihr könnt es ja mal mit metrischen Probieren, dann seht ihr schnell, warum das nicht gut ist.

Als erstes müssen wir das Paket ggplot2 installieren (*install.packages*) und aufrufen

```{r}
library(ggplot2)
```

Dann bauen wir ein erstes einfaches Säulendiagramm. Der Befehl für diese Art des Diagramms ist *geom_bar*. 

Die Information *data = * kann entweder direkt in die runden Klammern hinter ggplot() geschrieben werden ODER dem geom_bar hinzugefügt. 

Wie aber soll das Säulendiagramm (geom_bar) aussehen, welche Spalte des Datensatzes soll genau wie dargestellt werden? Das ist die Information die in *aes()* eingegeben werden muss.

Wir möchten jetzt also ein Säulendiagramm bauen, dass auf der x-Achse die verschiedenen Phasen des BACups-Datensatzes und die Häufigkeiten (wie viele Datensätze aus den verschiedenen Phasen gibt es) auf der y-Achse zeigt:

```{r}
ggplot()+ 
  geom_bar(data = BACups, aes(x = Phase)) 
```

Das + am Ende jeder Zeile sagt R, dass der Befehl in der nächsten Zeile weiter geht, ähnlich wie bei der pipe. 

Das ist doch schonmal was. Die Information die wir wollen, wird schnell und einfach angezeigt. 

Aber schön ist es noch nicht.

Geben wir den Achsen eine andere Beschriftung. Mit dem "labs"-Befehl lassen sich die Achsenbeschriftungen und die Überschriften ändern:
```{r erstes Säulendiagramm mit Achsen-Titel}
ggplot()+ 
  geom_bar(data = BACups, aes(x = Phase))+
  labs(y = "Häufigkeit",
       title = "Vorkommen der zwei Phasen")
```

Wir können auch die Säulen bunt einfärben. Der Befehl *fill* gibt den Balken unterschiedliche Farben, je nach den Angaben in der Spalte, die ich spezifiziere (hier wieder Phase):

```{r erstes Säulendiagramm und jetzt bunt!}
ggplot()+ 
  geom_bar(data = BACups, aes(x = Phase, fill = Phase))+
  labs(y = "Häufigkeit",
       title = "Vorkommen der zwei Phasen")

```

Oder einen anderen Look wählen (ein anderes Thema. Es gibt *theme_classic, theme_grey, theme_minimal* und *theme_bw*): 

```{r erstes Säulendiagramm mit anderem Thema}
ggplot(data = BACups)+ 
  geom_bar(aes(x = Phase, fill = Phase))+ 
  labs(y = "Häufigkeit",
       title = "Vorkommen der zwei Phasen")+
  theme_bw()
```


EXTRA Aufgabe:

Überlegt bitte, was in dem nächsten Code Chunk passiert. Die Hilfe kann mit ?Suchbegriff abgerufen werden.

```{r zweites Säulendiagramm}

data("EndScrapers")
ggplot(data = EndScrapers)+
  geom_col(aes(x = Site, fill = Width, y = Freq))+ 
  labs(y = "Häufigkeit",
       title = "Anzahl der Steinartefakte nach Breite und Fundort")+
  theme_bw() 

```

# Streudiagramme

Bei Streudiagrammen kann ich zwei Variablen gegeneinander plotten.

Wir tragen auf der X- und auf der Y-Achse metrische Daten ab. Das gehört zu den aesthetics-Elementen, deshalb tun wir die Info in die Klammern hinter *aes()*: 

```{r Streudiagramm basics}

ggplot(data = BACups)+
  geom_point(aes(x = RD, y = ND))

```

Jetzt können wir damit wieder die Dinge tun, die wir mit dem Balkendiagramm gemacht hatten, also die Achsen beschriften, einen Titel vergeben und den Style ändern:

```{r Streudiagramm mit Titel, mit x- und y-Achsenbeschriftung}
ggplot(data = BACups)+
  geom_point(aes(x = RD, y = ND)) + 
  labs(x =" Randdurchmesser",
       y ="Nackendurchmesser",
       title = "Rand- und Nackendurchmesser im Verhältnis zueinander")+
  theme_classic()

```

Was kann man noch tolles machen? 
Wie wäre es mit einer Linearen Regression?

Dafür fügen wir dem bestehenden Plot ein Layer hinzu. Der Befehl für Regressionslinien ist geom_smooth und wir benutzen die Methode "linear model" (lineare Regression), abgekürzt "lm" (es gibt noch mehr...). Mit *se* kann man den "standard error" hinzufügen (*se = TRUE*) oder nicht (*se = FALSE*). 

```{r}
ggplot(data = BACups)+
  geom_point(aes(x = RD, y = ND)) +
  geom_smooth(aes(x = RD, y = ND), method = "lm",
              se = TRUE)+
  labs(x =" Randdurchmesser",
       y ="Nackendurchmesser",
       title = "Rand- und Nackendurchmesser im Verhältnis zueinander")+
  theme_classic()

```



Was geht noch? 
Die Form und Farbe der Punkte von einer Variablen bestimmen lassen! 

Welches Merkmal, das ich in der Tabelle als Spalte aufgenommen habe die Form der Punkte bestimmt lege ich mit *shape* fest, die Farbe mit *color*.


```{r Streudiagramm mit schönen Punkten}

ggplot(data = BACups)+
  geom_point(aes(x = H, y = SD, shape = Phase, color = Phase)) + 
  labs(x =" Höhe des Gefäßes",
       y ="Schulterdurchmesser",
       title = "Höhe des Gefäßes im Verhältnis zum Schulterdurchmesser")+
  theme_bw()

```


Form und Farbe kann man natürlich auch von unterschiedlichen Parametern bestimmen lassen. Da diese Eigenschaften jedoch nominaler Art sein sollten und wir keinen zweiten nominale Variable in dem BACups-Datensatz haben, benutzen wir doch mal einen anderen. 

Die Snodgrass-Daten beinhalten "Information on the size, location and contents of 91 house pits at the Snodgrass site which was occupied between about CE 1325-1420". Ich schlag vor, ihr ladet ihn und schaut ihn euch kurz an:

```{r Snodgrass}
data("Snodgrass")
View(Snodgrass)
```

```{r Streudiagramm mit anderem Bsp}

ggplot(data = Snodgrass)+
  geom_point(aes(x = Width, y = Length, shape = Segment, color = Inside))+ 
  labs(x =" Breite des Hauses",
       y ="Länge des Hauses",
       title = "Häuser in Snodgrass")+
  theme_bw()

```

Hmmmhh, interessant. Aber ich vermute, der normale Leser des Diagramms kann nicht erkennen, was "Inside" für eine Information beinhaltet.
Kann man vllt die Beschriftung der Legende ändern?

Man kann!!

```{r Streudiagramm Legendenbeschriftung}

ggplot(data = Snodgrass)+
  geom_point(aes(x = Width, y = Length, shape = Segment, color = Inside))+ 
  labs(x = " Breite des Hauses",
       y = "Länge des Hauses",
       title = "Häuser in Snodgrass")+
  theme_bw()+
 scale_colour_discrete(name = "Innerhalb der Mauer oder nicht",
                            breaks = c("Inside","Outside"),
                            labels = c("innerhalb", "außerhalb")) +
scale_shape_discrete(name  ="Grabungsareal",
                           breaks = c("1","2","3"),
                           labels = c("Areal 1", "Areal 2", "Areal 3"))
```
Was bedeutet das alles?

Mit *scale_colour_discrete* kann ich Legenden (*scales*) verändern, die mit *color* innerhalb des aesthetics-Bereichs meines Codes für die Graphik definiert werden und die DISKRET sind (also v.a. nominale / ordinale Daten).

Hier benenne ich den Legendentitel mit *name = * um.

*breaks* bezeichnet die Werte in meiner Spalte, die dann mit den *labels* in der nächsten Zeile umbenannt werden.

Das gleiche kann ich mit der Legende für die FORM der Punkte machen: *scale_shape_discrete*.

Voll gut! 

## Facettierung!

Jetzt wird es nochmal richtig cool. 

Mit der Facettierung kann man ein oder zwei weitere Variablen auswählen, die den Datensatz unterteilen und in unterschiedlichen, aber gleich skalierten!, Graphiken darstellen. Es gibt zwei Möglichkeiten: *facet_grid()* und *facet_wrap()*. In beiden kann man ein bis zwei Variablen definieren, mit denen die Graphiken unterteilt werden. Während bei *facet_grid* immer alle Graphiken angezeigt werden, auch wenn sie leer sind, werden bei *facet_wrap* nur die angezeigt, in denen Daten vorkommen.

Vielleicht ein kleines Bsp: Im Snodgrass-Datensatz wollen wir die Breite und Länge der Häuser darstellen. Wir unterteilen die Plots aber danach, ob die Häuser innerhalb oder außerhalb der Mauer sind und danach, wie viele Figürinchen (effigies) in den Häusern gefunden wurden. Die Variablen, nach denen facettiert wird, werden mit ~ voneinander getrennt:

```{r}
ggplot(data = Snodgrass)+
  geom_point(aes(x = Width, y = Length))+
  facet_grid(Inside~Effigies)
```

Wie man sieht, gibt es einige Plots, die leer sind. *facet_wrap* bricht die rigide Gitterstruktur auf und zeigt nur die plots, die auch Daten beinhalten:

```{r}
ggplot(data = Snodgrass)+
  geom_point(aes(x = Width, y = Length))+
  facet_wrap(Inside~Effigies)
```

Sehr praktisch ist auch die Möglichkeit, hier die Variablen noch genauer zu spezifizieren. z.B. möchte ich gern nicht die genaue Anzahl von Figurinen, sondern nur ob es überhaupt welche in einem Haus gibt oder nicht der Information gegenüber stellen, ob sich das Haus innerhalb oder außerhalb der Mauer befindet: 

```{r}
library(sp)
coordinates(Snodgrass$East, Snodgrass$South)
ggplot(data = Snodgrass)+
  geom_point(aes(x = Width, y = Length))+
  facet_grid(Inside~Effigies > 0)

```



## Weiterführendes zu ggplot

ggplot hat noch viel viel mehr Möglichkeiten. Um das vorgeführt zu bekommen, empfehle ich den Blogpost hier zu lesen, der zeigt, wie sich so eine Visualisierung entwickeln kann und am Ende richtig richtig gut aussieht:
https://cedricscherer.netlify.com/2019/05/17/the-evolution-of-a-ggplot-ep.-1/

Hilfen, um mit ggplot zurechtzukommen sind: 

- die Schummelzettel: https://www.rstudio.com/wp-content/uploads/2015/06/ggplot2-german.pdf 

- dieses R-Intro-Buch: https://r-intro.tadaa-data.de/book/visualisierung.html

- das englische R-Cookbook: http://www.cookbook-r.com/ 




## weitere spannende Dinge in R:

Mit R kann man auch alle möglichen räumlichen Analysen machen. Man kann shape-files und raster-Daten bearbeiten. Ein kleines Beispiel, wie man eine einfache Karte plotten kann, lässt sich an dem Snodgrass-Datensatz zeigen

```{r}
ggplot()+
  geom_point(data = Snodgrass, aes(x = East, y = South))
```



- Rmarkdown: Text und Code in einem Dokument
dazu:
- The Definitive Guide: https://bookdown.org/yihui/rmarkdown/
- offizielle website: https://rmarkdown.rstudio.com/index.html

- sp, sf, spatstat, maptools: Pakete für räumliche Analysen

- rrtools: Projekt als R-Paket abspeichern (Text, Code und Daten in einem)


## eigene Daten einladen

Je nachdem, wie die eigenen Daten gespeichert sind, benötigt man unterschiedliche Funktionen in R. Was base-r am einfachsten kann, ist eine csv-Datei einladen. Der Befehl dafür heißt "read.csv2" (eine Weiterentwicklung von read.csv). Mit diesem Befehl können wir auch spezifizieren, mit welchem Zeichen die Spalten voneinander getrennt wurden. Im Beispiel gebe ich an, dass eine Semikolon-getrennte Tabelle ist. Außerdem ist es ein deutscher Datensatz und der Dezimaltrenner ist das Komma: 

```{r eval=FALSE, include=FALSE}
mydata <- read.csv2("Pfad/zur/Datei/meineDatei.csv", sep = ";", dec = ",")
```

Für Excel-Daten muss man ein eigenes Paket installieren. Ich empfehle "openxlsx". Hier kann ich z. B. spezifizieren, welches sheet in der Excel-Arbeitsmappe als Tabelle eingelesen werden soll:

```{r eval=FALSE, include=FALSE}
install.packages("openxlsx")
library(openxlsx)

mydata <- read.xlsx("Pfad/zur/Datei/meineDatei.xlsx", sheet = 1)
```








## Hilfestellungen					      15min
1. Hilfe-Funktion in R
2. Ben Marwicks page
3. Data Science Buch
4. YARRR 
5. google-tips
6. seekr.org

- das deutsche Wikibook zu R: https://de.wikibooks.org/wiki/GNU_R und 

- das englische R-Cookbook: http://www.cookbook-r.com/ 

- die 6 häufigsten Fehler: https://bookdown.org/chesterismay/rbasics/6-errors.html 
